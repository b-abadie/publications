<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Kubernetes networking and the outside world</title>

		<meta name="description" content="A presentation of Kubernetes networking models for communication with outside world on On Premise setups.">
		<meta name="author" content="Laurent CORBES <laurent.corbes@enix.fr>">


		<link rel="stylesheet" href="reveal.js/css/reveal.css">
		<link rel="stylesheet" href="reveal.js/css/theme/solarized.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="reveal.js/lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>

		<div class="reveal">
			<div class="slides">

				<section>
					<h3>Kubernetes networking and the outside world</h3>
					<h5>Story about how K8s chat with friends.</h5>
					<p>
						<small>By Laurent CORBES and  <a href="http://enix.io/">Enix</a> team</small>
					</p>
				</section>


				<section>
					Page de presentation ENIX
				</section>

				<section>
					<p>Pod to Pod network communication:</p>
					<ul>
						<li class="fragment"><a href="https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/">Plugin driven</a></li>
						<li class="fragment">Multiple providers</li>
						<li class="fragment">Almost plug and play</li>
					</ul>
					<h6 class="fragment">On all setups there is an "easy" solution.</h6>

					<aside class="notes">
						Le networking model Pod to Pod de kubernetes est maintenant mature, le systeme de plugin permet de facilement implementer ce que l'on veut. quelle que soit le besoin on trouvera une solution. Ca se change tres facilement, ce n'est plus un probleme aujourd'hui.
					</aside>
				</section>

				<section>
					<section>
					<p>External network communication:</p>
					<ul>
						<li class="fragment">External to K8s Services</li>
						<li class="fragment">Pods to external</li>
						<li class="fragment">External to Pods (Why not !)</li>
					</ul>

					<aside class="notes">
						La communication entre kubernetes et l'exterieur comprend 3 type de communications.
						La communication vers les services qui tournent dans K8s
						vers l'externe permet d'aller vers des ressources vers inernet, mais aussi des besoins de DB / services legacy dans des DMZ protege
					</aside>
					</section>

					<section>
					<p>External to Services</p>
					<ul>
						<li class="fragment"><a href="https://kubernetes.io/docs/concepts/services-networking/service/">Services driven</a></li>
						<li class="fragment">ClusterIP</li>
						<li class="fragment">NodePort</li>
					</ul>

					<aside class="notes">
						Mis en place grace au systeme de service.
						ClusterIP permet de mapper une ip de mon cluster a un service. cool mais ip interne seulement.
						NodePort permet d'exposer ce service aux ips externe de mon cluster. Cela se comprend dans le monde K8s ou tous les nodes sont la meme chose mais pas suffisant pour la redondance. pb de redondance dns load balancing etc... plusieurs services sur le meme port, ...
					</aside>
					</section>

					<section>
					<p>Pods to External</p>
					<ul>
						<li class="fragment">SNAT</li>
						<li class="fragment">Routing</li>
						<li class="fragment">CNI integration</li>
					</ul>

					<aside class="notes">
						En mode SNAT tout le cluster-ip-network tres simple a mettre en place. mais tres complique de filtrer dans un firewall / DMZ quelle ressource accede a la DB.
						En mode routage simple, possobilite de filtrage plus fin, mais si routes dynamique maintenance sur les nodes a faire.
						Certains CNI specialise fournissent une integration dans les modeles existant (Nuage, OVS, Calico)
					</aside>
					</section>
				</section>


				<section>
					<p>
						Standard modules not sufficient
					</p>
					<h3> Need some extra integration </h3>
					<aside class="notes">
						Il est necessaire de mettre en place de la glue et de l'integration entre les environnements exterieur specifique et k8s.

						Les possobilites sont trop nombreuses pour etre native a k8s.
					</aside>
				</section>

				<section>
					<h4>Cloud Providers world</h4>
					<ul>
						<li>K8s as a Service</li>
						<li>CNI driver</li>
						<li>Services load balancer</li>
					</ul>

					<aside class="notes">
						Regarder ce que les gros acteurs font.
						Dans le cas d'un K8s as a service tout est integre par le cloud provider.
						Integration d'un CNI driver qui permet de se plug nativement au networking model du provider.
						Integration d'un ingress load balancer qui profite des services propose de maniere generale par le cloud.
					</aside>
				</section>

				<section>
					<section>
						<h4>On Premise subworld</h4>
						<p>DiY</p>
						<aside class='notes'>
							Dans le monde maintenant underground du On premise, il faut tout faire soit meme en utilisant les briques les plus malignes possible en fonction de ses besoins.
						</aside>
					</section>

					<section>
						<h5>OpenStack</h5>
						<p>
							The Clone Wars
						</p>
						<ul>
							<li class="fragment"><a href="https://docs.openstack.org/kuryr-kubernetes/latest/readme.html#project-description">kuryr-kubernetes</a></li>
							<li class="fragment">Neutron LBaaS</li>
							<li class="fragment">Layer2 networking</li>
						</ul>

						<aside class="notes">
							Si on a la "chance" d'avoir une plateforme OpenStack il faut capitaliser sur l'existant.

							Utilisation du service de loadbalancing neutron. avec le plugin k8s dedie cela permet de piloter le LBaaS et allouer des ips de services directement depuis la configuration k8s.
							Utilisation du layer2 routing et allocation d'un cluster-network qui correspond au private network openstack. Penser a desactiver le network Spoofing.
						</aside>
				  </section>

					<section>
						<h5>Self made Load Balancer</h5>
						<p>
							No Pain, No Gain
						</p>
						<ul>
							<li class="fragment">Time consuming</li>
							<li class="fragment">Simple load balancer + NodePort</li>
							<li class="fragment">Dynamic with K8s API</li>
						</ul>

						<aside class="notes">
							On peut toujours se faire son propre load balancer. que ce soit en externe du cluster K8s ou en interne.
							Le resultat optinu dependra du temps investi.

							Le plus simple est d'exporter les services en utilisant la methode du NodePort et configurer le loadbalancer externe pour les utiliser
							Si besoin de dynamique faire des wrapper en utilisant de l'API k8s.

						</aside>
				  </section>

					<section>
						<h5>Kube-Router</h5>
						<p>
							Old pipes give sweetest smoke
						</p>
						<ul>
							<li class="fragment"><a href="https://kube-router.io/">https://kube-router.io/</a></li>
							<li class="fragment">BGP routing</li>
							<li class="fragment">IPVS loadbalancer</li>
						</ul>

						<aside class="notes">
							C'est avec les vieilles casseroles que l'on fait la meilleure soupe.
							C'est une combinaison des technologies BGP et ipvs. Ce ne sont pas des gros mots :)
							BGP fait fonctionner internet depuis 20ans de maniere plutot fiable et robuste. Fonctionne sur le principe des AS qui annonce ses IPS et permet de communiquer aux autres routeurs ses IPs et celle que l'on sait router.
							IPVS quand a lui est utilise dans les load balancers linux
						</aside>
					</section>
				</section>

				<section>
					<section>
						<h4>Kube-Router in details</h4>
						<aside class="notes">
							Comme on peut s'en douter Kube-Router est notre choix de predilection.
						</aside>
					</section>
					<section>
						<h5>Pod to Pod networking</h5>
						<ul>
							<li class="fragment">Fully Dynamic</li>
							<li class="fragment">Fully meshed</li>
							<li class="fragment">No NAT</li>
							<li class="fragment">Network Policy</li>
						</ul>
						<aside class="notes">
							Grace a BGP tout le routage interne au cluster est dynamique. Lors d'ajout de nodes le routage est automatiquement propage a tous les autre nodes.
							Le reseau est completement meshed. Tous les containers et nodes peuvent se parler entre eux sans limitations (par default, possobilite de network policy).
							Il y a aucun NAT, toutes les connections sont directe et les ips vu partout dans le reseau sont unique a un composant (node, container, service.)
							Network Policy base sur iptables
						</aside>
					</section>

					<section>
						<h5>Services </h5>
						<ul>
							<li class="fragment">Dynamic Loadbalancing</li>
							<li class="fragment">L4 TCP/UDP</li>
							<li class="fragment">SDR support</li>
						</ul>
						<aside class="notes">
							Supporte bien evidemment toute la dynamique des Pods par services en utilisant l'API k8s native. plusieurs modes de balancing suppporte (less used, equal, weight)
							IPVS ne supporte que le niveau 4 en mode TCP ou UDP. Il n'y a pas de niveau 7 http ni SSL
							Support le Direct Routing. Tres interessant pour les services necessitant beaucoup de bande passante descendante.
						</aside>
					</section>

					<section>
						<h5>BGP advertisement</h5>
						<ul>
							<li class="fragment">Any BGP router support</li>
							<li class="fragment">Cluster network and pod CIDRs</li>
							<li class="fragment">Services ClusterIP</li>
						</ul>
						<aside class="notes">
							C'est la que ca devient interessant.
							Supporte de peerer avec n'importe quel router BGP. Peut etre un node linux de routage quagga, zebra, goBGP, bird. un routeur coeur de reseau cisco,juniper,... ou un switch de feuille sur un DC en mode layer 3.
							Il exporte a ce routeur le routage interne des pods pour chaque node. Cela permet un routage direct entre le coeur de reseau et les nodes donc sans perte de performance. Et permet donc aux pods de se connecter en natif a un element externe au cluster. (legacy DB)
							Et ca marche pareil avec les ip de service defini par ClusterIP. elle sont elle aussi exporte en tant que /32 et ip anycast par chacun des nodes. Cela permet de faire du load balancing ECMP entre les nodes pour l'acces au service. et ainsi scale naturellement. La seule limite est la capacite ECMP du routeur au dessus du cluster.
						</aside>
					</section>


				</section>


				<section>
					<h3>Formation Kubernetes</h3>
					<small><p>
						Enix propose une formation <em>Déployer ses applications avec Kubernetes</em>.
					</p>
					<p>
						17/18 et 20/21 septembre 2018 à Paris
					</p>
					<p>
						<a href="https://enix.io/fr/services/formation/deployer-ses-applications-avec-kubernetes/">https://enix.io/fr/services/formation/deployer-ses-applications-avec-kubernetes/</a>. Contact: <a href="mailto:formation@enix.fr">formation@enix.fr</a>
					</p>

					</small>
				</section>

			</div>
		</div>


		<script src="reveal.js/lib/js/head.min.js"></script>
		<script src="reveal.js/js/reveal.js"></script>


		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				dependencies: [
					{ src: 'reveal.js/plugin/markdown/marked.js' },
					{ src: 'reveal.js/plugin/markdown/markdown.js' },
					{ src: 'reveal.js/plugin/notes/notes.js', async: true },
					{ src: 'reveal.js/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
